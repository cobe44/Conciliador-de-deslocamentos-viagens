"""
Processador de Deslocamentos v5
================================
Vers√£o com classifica√ß√£o baseada em VELOCIDADE:
- Processamento INCREMENTAL (sem DELETE destrutivo)
- Classifica√ß√£o V5: velocidade >= 3 km/h = movimento
- Consolida√ß√£o autom√°tica de per√≠odos curtos (< 5 min)
- Tratamento de per√≠odo "em curso" (n√£o insere se < 30 min)
- Rastreabilidade com raw_id_inicio e raw_id_fim
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime
from functools import lru_cache
from database import get_connection, get_placeholder, get_pois, migrate_db

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# Usar apenas a base
from poi_data import POIS_NUPORANGA, POI_RADIUS

# Importar configura√ß√µes centralizadas (com fallback se n√£o existir)
try:
    from config import (
        VELOCIDADE_MOVIMENTO, MIN_DURACAO_PERIODO, GAP_CONSOLIDACAO,
        TEMPO_PERIODO_EM_CURSO, GAP_THRESHOLD_MINUTES, STOP_THRESHOLD_KMH,
        MIN_DISTANCIA_VIAGEM, SIGNAL_LOSS_THRESHOLD, MAX_SPEED_REALISTIC,
        TEMPO_IGN_OFF_PARADA, DIST_REINICIO_DESLOCAMENTO, BATCH_SIZE
    )
except ImportError:
    # Fallback para valores padr√£o se config.py n√£o existir
    VELOCIDADE_MOVIMENTO = 3
    MIN_DURACAO_PERIODO = 5
    GAP_CONSOLIDACAO = 15
    TEMPO_PERIODO_EM_CURSO = 30
    GAP_THRESHOLD_MINUTES = 20
    STOP_THRESHOLD_KMH = 3
    MIN_DISTANCIA_VIAGEM = 2
    SIGNAL_LOSS_THRESHOLD = 60
    MAX_SPEED_REALISTIC = 150
    TEMPO_IGN_OFF_PARADA = 10
    DIST_REINICIO_DESLOCAMENTO = 3
    BATCH_SIZE = 50

# ==========================================
# GEOCODIFICA√á√ÉO (mantida do original)
# ==========================================
try:
    from geopy.geocoders import Nominatim
    from geopy.exc import GeocoderTimedOut, GeocoderServiceError
    GEOPY_AVAILABLE = True
except ImportError:
    GEOPY_AVAILABLE = False


def limpar_nome_local(nome):
    """
    Limpa nomes de localiza√ß√£o removendo prefixos verbosos.
    Ex: 'Regi√£o Geogr√°fica Imediata de Posse-Campos' -> 'Regi√£o de Posse-Campos'
    """
    if not nome:
        return nome
    
    # Substitui√ß√µes para limpar nomes
    substituicoes = [
        ('Regi√£o Geogr√°fica Imediata de ', 'Regi√£o de '),
        ('Regi√£o Geogr√°fica Intermedi√°ria de ', 'Regi√£o de '),
        ('Microrregi√£o de ', ''),
        ('Mesorregi√£o de ', ''),
    ]
    
    resultado = nome
    for antigo, novo in substituicoes:
        resultado = resultado.replace(antigo, novo)
    
    return resultado.strip()


@lru_cache(maxsize=4000)
def get_cached_city_name(lat, lon):
    """
    Geocodifica√ß√£o reversa com cache e arredondamento para maximizar hits.
    Arredonda para 3 casas (aprox 100m) para agrupar locais pr√≥ximos.
    """
    # Configura√ß√£o: False = tenta API, True = apenas POIs/coordenadas
    # Reativado conforme solicita√ß√£o do usu√°rio para garantir nomes
    SKIP_GEOCODING_API = False
    GEOCODING_TIMEOUT = 3  # Timeout maior para garantir resposta
    
    try:
        lat = float(lat)
        lon = float(lon)
        lat_r = round(lat, 3)
        lon_r = round(lon, 3)
    except (ValueError, TypeError):
        return "Coordenadas Inv√°lidas"
    
    # 1. Tentar Base Nuporanga (POIs locais) - sempre r√°pido
    for name, coords_list in POIS_NUPORANGA.items():
        for (p_lat, p_lon) in coords_list:
            if abs(lat_r - p_lat) < POI_RADIUS and abs(lon_r - p_lon) < POI_RADIUS:
                return name

    # 2. Se API desabilitada, retornar coordenada
    if SKIP_GEOCODING_API or not GEOPY_AVAILABLE:
        return f"{lat_r}, {lon_r}"
        
    try:
        # Geocodifica√ß√£o com timeout configurado
        geolocator = Nominatim(user_agent="frota_cf_v5", timeout=GEOCODING_TIMEOUT)
        loc = geolocator.reverse(f"{lat_r}, {lon_r}", language='pt')
        if loc and loc.address:
            address = loc.raw.get('address', {})
            city = address.get('city') or address.get('town') or address.get('municipality') or address.get('village')
            state = address.get('state')
            
            est_map = {
                'S√£o Paulo': 'SP', 'Minas Gerais': 'MG', 'Goi√°s': 'GO', 'Paran√°': 'PR',
                'Mato Grosso': 'MT', 'Mato Grosso do Sul': 'MS', 'Bahia': 'BA',
                'Rio de Janeiro': 'RJ', 'Santa Catarina': 'SC', 'Rio Grande do Sul': 'RS'
            }
            uf = est_map.get(state, state) if state else ""
            
            if city:
                nome = f"{city}/{uf}" if uf and len(uf) == 2 else city
                return limpar_nome_local(nome)
            return "Em Tr√¢nsito"
            
    except Exception:
        pass
        
    return f"{lat_r}, {lon_r}"


def classificar_tipo_parada(gap_minutos, ultima_ignicao, velocidade_media_antes):
    """
    Classifica o tipo de interrup√ß√£o no deslocamento.
    
    Retorna:
    - MOVIMENTO: Deslocamento normal
    - PARADA: Parada intencional (igni√ß√£o desligada ou baixa velocidade)
    - PERDA_SINAL: Prov√°vel perda de sinal GPS (gap longo com igni√ß√£o ligada)
    """
    if gap_minutos < GAP_THRESHOLD_MINUTES:
        return 'MOVIMENTO'
    
    # Igni√ß√£o desligada = parada intencional
    if ultima_ignicao == 0:
        return 'PARADA'
    
    # Gap muito longo com igni√ß√£o ligada = poss√≠vel perda de sinal
    if gap_minutos > SIGNAL_LOSS_THRESHOLD:
        return 'PERDA_SINAL'
    
    # Velocidade baixa antes do gap = provavelmente parada
    if velocidade_media_antes is not None and velocidade_media_antes < STOP_THRESHOLD_KMH:
        return 'PARADA'
    
    return 'MOVIMENTO'


def calcular_tempo_ocioso(trip_df):
    """
    Calcula tempo parado (velocidade < 3km/h) dentro de um deslocamento.
    Soma os intervalos de tempo onde o ve√≠culo estava parado.
    """
    if trip_df.empty or 'time_diff' not in trip_df.columns:
        return 0.0
    
    # Pontos onde velocidade < limiar
    parado_mask = trip_df['velocidade'] < STOP_THRESHOLD_KMH
    tempo_parado = trip_df.loc[parado_mask, 'time_diff'].sum()
    
    return float(tempo_parado) if not pd.isna(tempo_parado) else 0.0


def calcular_tempo_motor_off(trip_df):
    """
    Calcula tempo total com motor desligado na viagem:
    Soma do time_diff p/ pontos onde ignicao == 0
    """
    if trip_df.empty or 'time_diff' not in trip_df.columns:
        return 0.0
        
    # Filtrar pontos com igni√ß√£o 0
    pontos_off = trip_df[
        (trip_df['ignicao'] == 0) & 
        (trip_df['time_diff'].notna())
    ]
    return pontos_off['time_diff'].sum()


# ==========================================
# CLASSIFICADOR V5 - Baseado em Velocidade
# ==========================================
# Configura√ß√µes V5 importadas de config.py


def classificar_deslocamentos_v5(df):
    """
    Classificador V5 - L√≥gica baseada em VELOCIDADE com consolida√ß√£o autom√°tica
    
    Regras:
    - MOVIMENTO: velocidade >= 3 km/h
    - PARADA: velocidade < 3 km/h
    - Per√≠odos < 5 min s√£o consolidados com o adjacente do mesmo tipo
    - Gaps de at√© 15 min de parada dentro de um movimento n√£o fragmentam
    
    Returns:
        Lista de dicion√°rios com os per√≠odos classificados
    """
    resultados = []
    
    for placa in df['placa'].unique():
        df_placa = df[df['placa'] == placa].sort_values('data_hora').reset_index(drop=True)
        
        if df_placa.empty:
            continue
        
        # Calcular diferen√ßas
        df_placa['time_diff'] = df_placa['data_hora'].diff().dt.total_seconds() / 60
        
        # Classificar cada ponto como movimento ou parada baseado em velocidade
        df_placa['estado'] = df_placa['velocidade'].apply(
            lambda v: 'MOVIMENTO' if (v or 0) >= VELOCIDADE_MOVIMENTO else 'PARADA'
        )
        
        # PASSO 1: Criar per√≠odos brutos baseados em mudan√ßa de estado
        periodos_brutos = []
        estado_atual = None
        inicio_idx = 0
        
        for idx, row in df_placa.iterrows():
            if estado_atual is None:
                estado_atual = row['estado']
                inicio_idx = idx
            elif row['estado'] != estado_atual:
                # Mudou de estado - fechar per√≠odo anterior
                periodos_brutos.append({
                    'tipo': estado_atual,
                    'inicio_idx': inicio_idx,
                    'fim_idx': idx - 1,
                    'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                    'data_fim': df_placa.loc[idx - 1, 'data_hora'],
                })
                estado_atual = row['estado']
                inicio_idx = idx
        
        # √öltimo per√≠odo
        if estado_atual is not None:
            periodos_brutos.append({
                'tipo': estado_atual,
                'inicio_idx': inicio_idx,
                'fim_idx': len(df_placa) - 1,
                'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                'data_fim': df_placa.iloc[-1]['data_hora'],
            })
        
        # PASSO 2: Consolidar per√≠odos curtos
        periodos_consolidados = []
        
        for p in periodos_brutos:
            duracao = (p['data_fim'] - p['data_inicio']).total_seconds() / 60
            
            if not periodos_consolidados:
                periodos_consolidados.append(p)
                continue
            
            ultimo = periodos_consolidados[-1]
            gap = (p['data_inicio'] - ultimo['data_fim']).total_seconds() / 60
            
            # Regra 1: Se per√≠odo √© muito curto (< 5 min), absorver no anterior
            if duracao < MIN_DURACAO_PERIODO:
                # Estender o per√≠odo anterior at√© o fim deste
                ultimo['fim_idx'] = p['fim_idx']
                ultimo['data_fim'] = p['data_fim']
                continue
            
            # Regra 2: Se gap √© curto e s√£o do mesmo tipo, consolidar
            if gap <= GAP_CONSOLIDACAO and ultimo['tipo'] == p['tipo']:
                ultimo['fim_idx'] = p['fim_idx']
                ultimo['data_fim'] = p['data_fim']
                continue
            
            # Regra 3: Parada curta entre movimentos (ociosidade em tr√¢nsito) - absorver no movimento
            if (ultimo['tipo'] == 'MOVIMENTO' and p['tipo'] == 'PARADA' and 
                duracao < GAP_CONSOLIDACAO):
                # Verificar se o pr√≥ximo tamb√©m √© movimento
                # Por agora, mantemos como parada curta (ser√° tratado no pr√≥ximo loop)
                pass
            
            periodos_consolidados.append(p)
        
        # PASSO 3: Segunda passada - consolidar movimentos separados por paradas muito curtas
        periodos_final = []
        i = 0
        while i < len(periodos_consolidados):
            p = periodos_consolidados[i]
            
            if p['tipo'] == 'MOVIMENTO':
                # Verificar se podemos absorver paradas curtas √† frente
                while i + 2 < len(periodos_consolidados):
                    parada = periodos_consolidados[i + 1]
                    prox_mov = periodos_consolidados[i + 2]
                    
                    if parada['tipo'] == 'PARADA' and prox_mov['tipo'] == 'MOVIMENTO':
                        duracao_parada = (parada['data_fim'] - parada['data_inicio']).total_seconds() / 60
                        
                        if duracao_parada < GAP_CONSOLIDACAO:
                            # Absorver parada e pr√≥ximo movimento
                            p['fim_idx'] = prox_mov['fim_idx']
                            p['data_fim'] = prox_mov['data_fim']
                            i += 2
                        else:
                            break
                    else:
                        break
            
            periodos_final.append(p)
            i += 1
        
        # PASSO 4: Construir resultado final com todas as m√©tricas
        # Verificar se o √∫ltimo per√≠odo ainda est√° "em curso"
        agora = datetime.now()
        
        # Obter o √∫ltimo raw_id do lote processado para esta placa
        ultimo_raw_id_lote = df_placa['raw_id'].max()
        
        for idx_p, p in enumerate(periodos_final):
            inicio_idx = p['inicio_idx']
            fim_idx = p['fim_idx']
            
            data_fim_periodo = df_placa.loc[fim_idx, 'data_hora']
            raw_id_fim_periodo = df_placa.loc[fim_idx, 'raw_id']
            
            # Verificar se per√≠odo est√° "em curso" usando m√∫ltiplos crit√©rios:
            # 1. √â o √∫ltimo per√≠odo da placa
            # 2. Terminou h√° menos de 60 minutos OU raw_id_fim √© o √∫ltimo do lote
            is_ultimo = (idx_p == len(periodos_final) - 1)
            tempo_desde_fim = (agora - data_fim_periodo.to_pydatetime().replace(tzinfo=None)).total_seconds() / 60
            is_ultimo_raw_id = (raw_id_fim_periodo == ultimo_raw_id_lote)
            
            # Per√≠odo em curso se: √© o √∫ltimo E (terminou recentemente OU √© o √∫ltimo ponto recebido)
            if is_ultimo and (tempo_desde_fim < 60 or is_ultimo_raw_id):
                # Per√≠odo ainda em curso, pular para pr√≥xima execu√ß√£o
                logger.info(f"‚è≥ Per√≠odo em curso ignorado: {placa} {p['tipo']} (raw_id_fim={raw_id_fim_periodo}, √∫ltimo={ultimo_raw_id_lote})")
                continue
            
            resultados.append({
                'placa': placa,
                'tipo': 'DESLOCAMENTO' if p['tipo'] == 'MOVIMENTO' else 'PARADA',
                'inicio_idx': inicio_idx,
                'fim_idx': fim_idx,
                'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                'data_fim': df_placa.loc[fim_idx, 'data_hora'],
                'odo_inicio': df_placa.loc[inicio_idx, 'odometro'],
                'odo_fim': df_placa.loc[fim_idx, 'odometro'],
                'raw_id_inicio': df_placa.loc[inicio_idx, 'raw_id'],
                'raw_id_fim': df_placa.loc[fim_idx, 'raw_id'],
                'lat_inicio': df_placa.loc[inicio_idx, 'latitude'],
                'lon_inicio': df_placa.loc[inicio_idx, 'longitude'],
                'lat_fim': df_placa.loc[fim_idx, 'latitude'],
                'lon_fim': df_placa.loc[fim_idx, 'longitude'],
            })
    
    return resultados


def classificar_deslocamentos_v4(df):
    """
    Classificador V4 - L√≥gica baseada em igni√ß√£o + dist√¢ncia
    
    Regras:
    - DESLOCAMENTO: igni√ß√£o=1 constante, TERMINA quando igni√ß√£o=0 por 10+ min
    - PARADA: inicia no primeiro igni√ß√£o=0, TERMINA quando igni√ß√£o=1 E dist>=3km
    - OCIOSIDADE: igni√ß√£o=1 mas parado - N√ÉO inicia novo deslocamento
    
    Args:
        df: DataFrame com colunas [raw_id, placa, data_hora, ignicao, velocidade, odometro, lat, lon]
    
    Returns:
        Lista de dicion√°rios com os per√≠odos classificados
    """
    resultados = []
    
    # Processar por placa
    for placa in df['placa'].unique():
        df_placa = df[df['placa'] == placa].sort_values('data_hora').reset_index(drop=True)
        
        if df_placa.empty:
            continue
        
        # Calcular diferen√ßa de tempo entre posi√ß√µes
        df_placa['time_diff'] = df_placa['data_hora'].diff().dt.total_seconds() / 60
        
        estado = None  # 'DESLOCAMENTO' ou 'PARADA'
        inicio_idx = 0
        odo_inicio_parada = None
        tempo_ign_off_acumulado = 0
        
        for idx, row in df_placa.iterrows():
            ignicao = row['ignicao'] or 0
            velocidade = row['velocidade'] or 0
            time_diff = row['time_diff'] if pd.notna(row['time_diff']) else 0
            odometro = row['odometro'] or 0
            
            if estado is None:
                # Primeiro ponto
                if ignicao == 1:
                    estado = 'DESLOCAMENTO'
                    inicio_idx = idx
                    tempo_ign_off_acumulado = 0
                else:
                    estado = 'PARADA'
                    inicio_idx = idx
                    odo_inicio_parada = odometro
                    
            elif estado == 'DESLOCAMENTO':
                if ignicao == 0:
                    tempo_ign_off_acumulado += time_diff
                    if tempo_ign_off_acumulado >= TEMPO_IGN_OFF_PARADA:
                        # Fecha deslocamento - buscar √∫ltimo ponto com igni√ß√£o=1
                        fim_deslocamento_idx = idx
                        for back_idx in range(idx, inicio_idx, -1):
                            if df_placa.loc[back_idx, 'ignicao'] == 1:
                                fim_deslocamento_idx = back_idx
                                break
                        
                        resultados.append({
                            'placa': placa,
                            'tipo': 'DESLOCAMENTO',
                            'inicio_idx': inicio_idx,
                            'fim_idx': fim_deslocamento_idx,
                            'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                            'data_fim': df_placa.loc[fim_deslocamento_idx, 'data_hora'],
                            'odo_inicio': df_placa.loc[inicio_idx, 'odometro'],
                            'odo_fim': df_placa.loc[fim_deslocamento_idx, 'odometro'],
                            'raw_id_inicio': df_placa.loc[inicio_idx, 'raw_id'],
                            'raw_id_fim': df_placa.loc[fim_deslocamento_idx, 'raw_id'],
                            'lat_inicio': df_placa.loc[inicio_idx, 'latitude'],
                            'lon_inicio': df_placa.loc[inicio_idx, 'longitude'],
                            'lat_fim': df_placa.loc[fim_deslocamento_idx, 'latitude'],
                            'lon_fim': df_placa.loc[fim_deslocamento_idx, 'longitude'],
                        })
                        
                        # Inicia parada
                        estado = 'PARADA'
                        for p_idx in range(fim_deslocamento_idx + 1, idx + 1):
                            if df_placa.loc[p_idx, 'ignicao'] == 0:
                                inicio_idx = p_idx
                                break
                        else:
                            inicio_idx = idx
                        
                        odo_inicio_parada = df_placa.loc[inicio_idx, 'odometro']
                        tempo_ign_off_acumulado = 0
                else:
                    # igni√ß√£o=1, continua deslocamento
                    tempo_ign_off_acumulado = 0
                        
            elif estado == 'PARADA':
                if ignicao == 1:
                    dist_desde_parada = abs(odometro - odo_inicio_parada) if odo_inicio_parada else 0
                    if dist_desde_parada >= DIST_REINICIO_DESLOCAMENTO:
                        # Fecha parada - buscar √∫ltimo ponto com igni√ß√£o=0
                        fim_parada_idx = idx
                        for back_idx in range(idx, inicio_idx, -1):
                            if df_placa.loc[back_idx, 'ignicao'] == 0:
                                fim_parada_idx = back_idx
                                break
                        
                        resultados.append({
                            'placa': placa,
                            'tipo': 'PARADA',
                            'inicio_idx': inicio_idx,
                            'fim_idx': fim_parada_idx,
                            'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                            'data_fim': df_placa.loc[fim_parada_idx, 'data_hora'],
                            'odo_inicio': df_placa.loc[inicio_idx, 'odometro'],
                            'odo_fim': df_placa.loc[fim_parada_idx, 'odometro'],
                            'raw_id_inicio': df_placa.loc[inicio_idx, 'raw_id'],
                            'raw_id_fim': df_placa.loc[fim_parada_idx, 'raw_id'],
                            'lat_inicio': df_placa.loc[inicio_idx, 'latitude'],
                            'lon_inicio': df_placa.loc[inicio_idx, 'longitude'],
                            'lat_fim': df_placa.loc[fim_parada_idx, 'latitude'],
                            'lon_fim': df_placa.loc[fim_parada_idx, 'longitude'],
                        })
                        
                        # Inicia novo deslocamento
                        estado = 'DESLOCAMENTO'
                        for d_idx in range(fim_parada_idx + 1, idx + 1):
                            if df_placa.loc[d_idx, 'ignicao'] == 1:
                                inicio_idx = d_idx
                                break
                        else:
                            inicio_idx = idx
                        
                        tempo_ign_off_acumulado = 0
                    # Se dist < 3km, continua na parada (ociosidade)
        
        # Fechar √∫ltimo per√≠odo
        if estado is not None and len(df_placa) > 0:
            last_idx = len(df_placa) - 1
            resultados.append({
                'placa': placa,
                'tipo': estado,
                'inicio_idx': inicio_idx,
                'fim_idx': last_idx,
                'data_inicio': df_placa.loc[inicio_idx, 'data_hora'],
                'data_fim': df_placa.iloc[-1]['data_hora'],
                'odo_inicio': df_placa.loc[inicio_idx, 'odometro'],
                'odo_fim': df_placa.iloc[-1]['odometro'],
                'raw_id_inicio': df_placa.loc[inicio_idx, 'raw_id'],
                'raw_id_fim': df_placa.iloc[-1]['raw_id'],
                'lat_inicio': df_placa.loc[inicio_idx, 'latitude'],
                'lon_inicio': df_placa.loc[inicio_idx, 'longitude'],
                'lat_fim': df_placa.iloc[-1]['latitude'],
                'lon_fim': df_placa.iloc[-1]['longitude'],
            })
    
    return resultados

    conn.close()
    return ultimo_id


def obter_ultimo_estado_banco(placa):
    """
    V6: Busca o √∫ltimo registro de deslocamento/parada do ve√≠culo no banco.
    Isso permite continuar o estado anterior (evitando gaps) em vez de come√ßar do zero.
    """
    conn = get_connection()
    c = conn.cursor()
    
    # Busca o √∫ltimo registro (seja CONCLUIDO ou EM_CURSO)
    query = """
    SELECT id, tipo_parada, data_inicio, data_fim, km_inicial, km_final, 
           distancia, local_inicio, local_fim, raw_id_fim
    FROM deslocamentos 
    WHERE placa = %s 
    ORDER BY data_fim DESC, id DESC 
    LIMIT 1
    """
    
    try:
        c.execute(query, (placa,))
        row = c.fetchone()
        
        if row:
            # Converter para dicion√°rio de estado
            return {
                'id': row[0],
                'tipo': 'MOVIMENTO' if row[1] == 'MOVIMENTO' else 'PARADA', # Normalizar nome
                'data_fim': pd.to_datetime(row[3]),
                'km_final': row[5],
                'local_fim': row[8],
                'raw_id_fim': row[9]
            }
    except Exception as e:
        logger.error(f"Erro ao buscar √∫ltimo estado para {placa}: {e}")
        
    conn.close()
    return None

def classificar_deslocamentos_v6_persistente(df, estado_atual=None):
    """
    Classificador V6 - M√°quina de Estados Persistente
    
    Diferente do V5, este classificador leva em conta o √∫ltimo estado gravado no banco.
    
    Cen√°rios:
    1. Sem estado anterior: Inicia l√≥gica V5 normal
    2. Anterior = MOVIMENTO:
       - Novos dados continuam movendo? -> UPDATE registro anterior (estende data_fim)
       - Parou? -> UPDATE registro anterior (fecha) + INSERT nova Parada (inicia onde mov terminou)
       
    3. Anterior = PARADA:
       - Novos dados continuam parados? -> UPDATE registro anterior
       - Moveu? -> UPDATE registro anterior (fecha) + INSERT novo Movimento
       
    Returns:
        updates: Lista de atualiza√ß√µes em registros existentes
        inserts: Lista de novos registros a criar
        novo_estado: O estado final ap√≥s processar o lote
    """
    updates = []
    inserts = []
    
    # Se n√£o temos dados novos, retorna nada
    if df.empty:
        return updates, inserts, estado_atual

    # Ordenar por garantia
    df = df.sort_values('data_hora').reset_index(drop=True)
    
    # Calcular m√©tricas b√°sicas para an√°lise (velocidade, tempo, dist)
    df['time_diff'] = df['data_hora'].diff().dt.total_seconds() / 60
    
    # L√≥gica de Estado
    # Se n√£o tem estado anterior, assumimos o primeiro ponto como in√≠cio de algo
    if estado_atual is None:
        # Tenta inferir pelo primeiro ponto
        primeiro = df.iloc[0]
        vel = primeiro['velocidade']
        tipo_inicial = 'MOVIMENTO' if vel >= VELOCIDADE_MOVIMENTO else 'PARADA'
        
        # Cria um estado virtual "novo" para come√ßar a processar
        estado_atual = {
            'id': None, # None indica que √© um registro novo, ainda n√£o salvo
            'tipo': tipo_inicial,
            'inicio_idx': 0,
            'data_inicio': primeiro['data_hora'],
            'data_fim': primeiro['data_hora'],
            'raw_id_fim': primeiro['raw_id']
        }
    
    # Processar ponto a ponto (ou em blocos para performance)
    # Por simplicidade e robustez V6, vamos iterar e detectar transi√ß√µes
    
    # Processar ponto a ponto para detectar transi√ß√µes
    pontos = df.to_dict('records')
    
    # Se estado_atual veio do banco, precisamos carregar seu 'contexto' (ID, tipo)
    current_state_type = estado_atual['tipo']
    current_db_id = estado_atual.get('id')
    current_start_idx = 0  # √çndice relativo ao DF atual onde come√ßou este segmento
    
    # Buffer para confirmar transi√ß√£o
    transition_buffer = []  # Lista de pontos candidatos a mudan√ßa
    
    for i, p in enumerate(pontos):
        # Determinar estado instant√¢neo deste ponto
        is_moving = p['velocidade'] >= VELOCIDADE_MOVIMENTO
        point_type = 'MOVIMENTO' if is_moving else 'PARADA'
        
        # L√≥gica de Confirma√ß√£o de Transi√ß√£o
        if point_type != current_state_type:
            # Potencial mudan√ßa de estado! Adicionar ao buffer
            transition_buffer.append(p)
            
            # Verificar se confirmamos a mudan√ßa
            start_transition = transition_buffer[0]['data_hora']
            end_transition = p['data_hora']
            duration_minutes = (end_transition - start_transition).total_seconds() / 60
            
            confirm_threshold = GAP_CONSOLIDACAO if current_state_type == 'MOVIMENTO' else MIN_DURACAO_PERIODO
            
            if duration_minutes >= confirm_threshold:
                # MUDAN√áA CONFIRMADA!
                # A mudan√ßa aconteceu em transition_buffer[0] (retroativo)
                transition_start_point = transition_buffer[0]
                
                # 1. Fechar estado anterior (current)
                # Se tem ID, √© UPDATE. Se n√£o, √© INSERT de um novo fechado.
                prev_end_point = pontos[i - len(transition_buffer)] # Ponto antes da transi√ß√£o come√ßar
                
                # Se n√£o houver ponto anterior no DF (mudan√ßa logo no in√≠cio), usar o pr√≥prio in√≠cio da transi√ß√£o
                # como fim do anterior (continuidade perfeita)
                data_fim_anterior = transition_start_point['data_hora']
                
                if current_db_id:
                    # UPDATE registro existente no banco
                    updates.append({
                        'id': current_db_id,
                        'data_fim': data_fim_anterior,
                        'km_final': transition_start_point['odometro'], # Aproximado
                        'local_fim': f"{transition_start_point['latitude']}, {transition_start_point['longitude']}", # Ser√° geocodificado depois
                        'raw_id_fim': transition_start_point['raw_id']
                    })
                else:
                    # CORRE√á√ÉO V6: Fechar o INSERT anterior que ainda estava aberto
                    # Isso acontece quando h√° m√∫ltiplas transi√ß√µes no mesmo lote
                    if inserts:
                        # Preencher data_fim do √∫ltimo insert com o momento da transi√ß√£o
                        inserts[-1]['data_fim'] = data_fim_anterior
                        inserts[-1]['km_final'] = transition_start_point['odometro']
                        inserts[-1]['local_fim'] = f"{transition_start_point['latitude']}, {transition_start_point['longitude']}"
                        inserts[-1]['raw_id_fim'] = transition_start_point['raw_id']
                
                # 2. Iniciar novo estado
                current_state_type = point_type
                current_db_id = None # Novo estado, ainda n√£o tem ID no banco
                current_start_idx = i - len(transition_buffer) + 1 # Ajustar √≠ndice (aprox)
                transition_buffer = [] # Limpar buffer
                
                # Adicionar novo registro para INSERT
                inserts.append({
                    'tipo': current_state_type,
                    'data_inicio': data_fim_anterior, # In√≠cio = Fim do anterior (GAP ZERO)
                    'km_inicial': transition_start_point['odometro'],
                    'local_inicio': f"{transition_start_point['latitude']}, {transition_start_point['longitude']}",
                    'raw_id_inicio': transition_start_point['raw_id'],
                    # Fim ser√° definido quando fechar ou no final do lote
                })
                
        else:
            # Ponto confirma o estado atual (resetar buffer de transi√ß√£o)
            # Ex: Estava MOVIMENTO, veio PARADA, PARADA (buffer), depois MOVIMENTO (reset)
            if transition_buffer:
                transition_buffer = []
        
    # Fim do loop: O que sobrou √© o estado atual "EM CURSO"
    # Precisamos atualizar o registro correspondente (seja UPDATE no banco ou UPDATE no INSERT pendente)
    
    ultimo_ponto = pontos[-1]
    
    if current_db_id:
        # O estado continuou o mesmo do banco o tempo todo (ou desde a √∫ltima transi√ß√£o confirmada)
        updates.append({
            'id': current_db_id,
            'data_fim': ultimo_ponto['data_hora'],
            'km_final': ultimo_ponto['odometro'],
            'local_fim': f"{ultimo_ponto['latitude']}, {ultimo_ponto['longitude']}",
            'raw_id_fim': ultimo_ponto['raw_id']
        })
    elif inserts:
        # Temos um insert novo aberto, vamos fechar ele no fim deste lote
        inserts[-1]['data_fim'] = ultimo_ponto['data_hora']
        inserts[-1]['km_final'] = ultimo_ponto['odometro']
        inserts[-1]['local_fim'] = f"{ultimo_ponto['latitude']}, {ultimo_ponto['longitude']}"
        inserts[-1]['raw_id_fim'] = ultimo_ponto['raw_id']
    else:
        # Caso raro: Estado novo desde o in√≠cio mas sem transi√ß√£o anterior
        # (Ex: Primeiro dado da vida do caminh√£o)
        inserts.append({
            'tipo': current_state_type,
            'data_inicio': pontos[0]['data_hora'],
            'km_inicial': pontos[0]['odometro'],
            'local_inicio': f"{pontos[0]['latitude']}, {pontos[0]['longitude']}",
            'raw_id_inicio': pontos[0]['raw_id'],
            'data_fim': ultimo_ponto['data_hora'],
            'km_final': ultimo_ponto['odometro'],
            'local_fim': f"{ultimo_ponto['latitude']}, {ultimo_ponto['longitude']}",
            'raw_id_fim': ultimo_ponto['raw_id']
        })

    # Retornar o novo estado para o pr√≥ximo lote (se precisarmos em mem√≥ria)
    novo_estado = {
        'tipo': current_state_type,
        'id': current_db_id or 'PENDING_INSERT'
    }

    return updates, inserts, novo_estado



def obter_ultimo_raw_id_processado():
    """
    Busca o maior raw_id_fim j√° processado.
    Permite processamento incremental sem reprocessar dados antigos.
    """
    conn = get_connection()
    c = conn.cursor()
    
    try:
        c.execute("SELECT MAX(raw_id_fim) FROM deslocamentos WHERE raw_id_fim IS NOT NULL")
        result = c.fetchone()
        ultimo_id = result[0] if result and result[0] else 0
    except Exception as e:
        # Coluna pode n√£o existir em bancos antigos
        # print(f"‚ö†Ô∏è Erro ao buscar √∫ltimo ID processado: {e}")
        ultimo_id = 0
    
    conn.close()
    return ultimo_id

def processar_deslocamentos(reprocessar_tudo=False):
    """
    Processador V6 - Estado Persistente
    
    L√≥gica baseada em M√°quina de Estados que persiste no banco para eliminar gaps.
    Sempre carrega o √∫ltimo estado do banco e continua a partir dele.
    """
    print("üöÄ Iniciando Processador V6 (Estado Persistente)...")
    
    # Garantir que as novas colunas existam
    try:
        migrate_db()
    except Exception as e:
        print(f"‚ö†Ô∏è Migra√ß√£o: {e}")
    
    conn = get_connection()
    c = conn.cursor()
    
    # Determinar ponto de in√≠cio
    if reprocessar_tudo:
        ultimo_id = 0
        print("‚ö†Ô∏è Modo REPROCESSAR TUDO ativado")
    else:
        ultimo_id = obter_ultimo_raw_id_processado()
        print(f"üìç √öltimo raw_id processado: {ultimo_id}")
    
    # 1. Carregar apenas dados NOVOS (incremental)
    query = f"""
        SELECT 
            p.id AS raw_id,
            p.id_veiculo, 
            v.placa, 
            p.data_hora, 
            p.latitude, 
            p.longitude, 
            p.odometro, 
            p.ignicao, 
            p.velocidade
        FROM posicoes_raw p
        JOIN veiculos v ON p.id_veiculo = v.id_sascar
        WHERE p.id > %s
        ORDER BY p.id_veiculo, p.data_hora
    """
    
    try:
        df = pd.read_sql(query, conn, params=(ultimo_id,))
    except Exception as e:
        print(f"Erro ao ler dados: {e}")
        conn.close()
        return []
    
    if df.empty:
        print("‚úÖ Nenhum dado novo para processar.")
        conn.close()
        return []
    
    print(f"üì¶ Dados novos carregados: {len(df)} linhas")
    
    # Converter data
    df['data_hora'] = pd.to_datetime(df['data_hora'])
    
    print("üîÑ Classificando com L√≥gica V6 (M√°quina de Estados Persistente)...")
    
    total_updates = 0
    total_inserts = 0
    placas_processadas = 0
    
    for placa in df['placa'].unique():
        df_placa = df[df['placa'] == placa].copy()
        placas_processadas += 1
        
        # Carregar √∫ltimo estado do banco
        estado_banco = obter_ultimo_estado_banco(placa)
        
        # Rodar classificador V6
        updates, inserts, novo_estado = classificar_deslocamentos_v6_persistente(df_placa, estado_banco)
        
        # Executar UPDATES
        if updates:
            total_updates += len(updates)
            for upd in updates:
                # Geocodificar local_fim se for coordenada
                local_fim_raw = upd.get('local_fim', '')
                try:
                    parts = local_fim_raw.split(',')
                    if len(parts) == 2:
                        lat, lon = float(parts[0].strip()), float(parts[1].strip())
                        local_fim = get_cached_city_name(lat, lon)
                    else:
                        local_fim = local_fim_raw
                except:
                    local_fim = local_fim_raw
                    
                c.execute("""
                    UPDATE deslocamentos 
                    SET data_fim = %s, km_final = %s, local_fim = %s, raw_id_fim = %s,
                        tempo = EXTRACT(EPOCH FROM (%s - data_inicio))/60
                    WHERE id = %s
                """, (
                    upd['data_fim'], upd['km_final'], local_fim, upd['raw_id_fim'],
                    upd['data_fim'], upd['id']
                ))
        
        # Executar INSERTS
        if inserts:
            total_inserts += len(inserts)
            for ins in inserts:
                dist = (ins.get('km_final', 0) - ins['km_inicial']) if 'km_final' in ins else 0
                
                # Inicia como 'PENDENTE' para aparecer na interface de fechamento
                # Podemos tamb√©m usar 'EM_CURSO' se ainda n√£o fechou, mas interface filtra PENDENTE
                status = 'PENDENTE'
                
                # CORRE√á√ÉO V6: Se o registro √© EM_CURSO, ele pode n√£o ter data_fim definida ainda no dicion√°rio ins.
                # Mas o banco exige NOT NULL. Ent√£o usamos a √∫ltima data conhecida como data_fim provis√≥ria.
                # A l√≥gica V6 vai estender essa data via UPDATE nas pr√≥ximas execu√ß√µes.
                
                dt_fim = ins.get('data_fim', ins['data_inicio']) # Se n√£o tem fim, fim = inicio (dura√ß√£o 0)
                km_final = ins.get('km_final', ins['km_inicial'])
                raw_id_fim = ins.get('raw_id_fim', ins['raw_id_inicio'])
                
                # GEOCODIFICA√á√ÉO DIRETA: Converter lat/long para nomes de cidades
                # O local_inicio e local_fim v√™m como "lat, lon" do classificador
                local_inicio_raw = ins.get('local_inicio', '')
                local_fim_raw = ins.get('local_fim', ins.get('local_inicio', ''))
                
                # Extrair lat/lon e geocodificar
                try:
                    parts_ini = local_inicio_raw.split(',')
                    if len(parts_ini) == 2:
                        lat_i, lon_i = float(parts_ini[0].strip()), float(parts_ini[1].strip())
                        local_inicio = get_cached_city_name(lat_i, lon_i)
                    else:
                        local_inicio = local_inicio_raw
                except:
                    local_inicio = local_inicio_raw
                
                try:
                    parts_fim = local_fim_raw.split(',')
                    if len(parts_fim) == 2:
                        lat_f, lon_f = float(parts_fim[0].strip()), float(parts_fim[1].strip())
                        local_fim = get_cached_city_name(lat_f, lon_f)
                    else:
                        local_fim = local_fim_raw
                except:
                    local_fim = local_fim_raw
                
                c.execute("""
                    INSERT INTO deslocamentos (
                        placa, tipo_parada, data_inicio, data_fim, 
                        km_inicial, km_final, distancia, 
                        local_inicio, local_fim, 
                        raw_id_inicio, raw_id_fim,
                        status
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    placa, ins['tipo'], ins['data_inicio'], dt_fim,
                    ins['km_inicial'], km_final, dist,
                    local_inicio, local_fim,
                    ins['raw_id_inicio'], raw_id_fim,
                    status
                ))
        
        conn.commit()
    
    print("\n" + "="*50)
    print("üìä RESUMO DO PROCESSAMENTO V6")
    print("="*50)
    print(f"  Placas processadas: {placas_processadas}")
    print(f"  Registros atualizados: {total_updates}")
    print(f"  Novos registros: {total_inserts}")
    
    conn.close()
    
    # 3. Geo-decodifica√ß√£o ass√≠ncrona (Backfill)
    try:
        from backfill_names import processar_backfill
        print("üåç Iniciando backfill de geocodifica√ß√£o...")
        processar_backfill()
    except Exception as e:
        print(f"‚ö†Ô∏è Erro no backfill: {e}")
        
    return [] # Compatibilidade + 1


def consolidar_periodos_consecutivos(tolerancia_minutos=30):
    """
    Consolida paradas e movimentos consecutivos do mesmo ve√≠culo no mesmo local.
    
    Esta fun√ß√£o agrupa registros fragmentados que deveriam ser um √∫nico per√≠odo.
    Por exemplo: v√°rios registros de PARADA de 20-30 minutos consecutivos
    s√£o consolidados em um √∫nico registro de PARADA de v√°rias horas.
    
    Args:
        tolerancia_minutos: Gap m√°ximo entre per√≠odos para considerar como consecutivos (default: 30)
    
    Regras de consolida√ß√£o:
    - PARADAS consecutivas: mesmo local_inicio, gap < toler√¢ncia
    - MOVIMENTOS consecutivos: local_fim do anterior = local_inicio do pr√≥ximo, gap < toler√¢ncia
    """
    print(f"üîÑ Iniciando consolida√ß√£o de per√≠odos consecutivos (toler√¢ncia: {tolerancia_minutos} min)...")
    
    conn = get_connection()
    c = conn.cursor()
    
    # Buscar deslocamentos pendentes ordenados por placa e data
    c.execute("""
        SELECT id, placa, tipo_parada, data_inicio, data_fim, 
               km_inicial, km_final, distancia, local_inicio, local_fim,
               tempo, tempo_ocioso, tempo_motor_off, qtd_pontos,
               raw_id_inicio, raw_id_fim
        FROM deslocamentos 
        WHERE status = 'PENDENTE'
        ORDER BY placa, data_inicio
    """)
    
    registros = c.fetchall()
    
    if not registros:
        print("‚ÑπÔ∏è Nenhum deslocamento pendente para consolidar.")
        conn.close()
        return
    
    print(f"üì¶ {len(registros)} registros pendentes encontrados.")
    
    # Agrupar por placa
    registros_por_placa = {}
    for reg in registros:
        placa = reg[1]
        if placa not in registros_por_placa:
            registros_por_placa[placa] = []
        registros_por_placa[placa].append({
            'id': reg[0],
            'placa': reg[1],
            'tipo': reg[2],
            'data_inicio': pd.to_datetime(reg[3]),
            'data_fim': pd.to_datetime(reg[4]),
            'km_inicial': reg[5] or 0,
            'km_final': reg[6] or 0,
            'distancia': reg[7] or 0,
            'local_inicio': reg[8],
            'local_fim': reg[9],
            'tempo': reg[10] or 0,
            'tempo_ocioso': reg[11] or 0,
            'tempo_motor_off': reg[12] or 0,
            'qtd_pontos': reg[13] or 0,
            'raw_id_inicio': reg[14],
            'raw_id_fim': reg[15],
        })
    
    ids_para_deletar = []
    registros_para_atualizar = []
    total_consolidados = 0
    
    for placa, lista_reg in registros_por_placa.items():
        if len(lista_reg) < 2:
            continue
        
        i = 0
        while i < len(lista_reg):
            reg_atual = lista_reg[i]
            grupo = [reg_atual]
            
            # Buscar consecutivos que podem ser consolidados
            j = i + 1
            while j < len(lista_reg):
                reg_prox = lista_reg[j]
                
                # Calcular gap entre fim do atual e in√≠cio do pr√≥ximo
                gap = (reg_prox['data_inicio'] - grupo[-1]['data_fim']).total_seconds() / 60
                
                # Verificar se pode consolidar
                pode_consolidar = False
                
                if gap <= tolerancia_minutos:
                    # Mesmo tipo (PARADA com PARADA, MOVIMENTO com MOVIMENTO)
                    if reg_atual['tipo'] == reg_prox['tipo']:
                        # V5: Sempre consolida se mesmo tipo e gap pequeno
                        # Ignora compara√ß√£o de local (coordenadas GPS variam levemente)
                        pode_consolidar = True
                
                if pode_consolidar:
                    grupo.append(reg_prox)
                    j += 1
                else:
                    break
            
            # Se temos mais de 1 registro no grupo, consolidar
            if len(grupo) > 1:
                primeiro = grupo[0]
                ultimo = grupo[-1]
                
                # Calcular m√©tricas agregadas
                tempo_total = (ultimo['data_fim'] - primeiro['data_inicio']).total_seconds() / 60
                distancia_total = sum(r['distancia'] for r in grupo)
                tempo_ocioso_total = sum(r['tempo_ocioso'] for r in grupo)
                tempo_motor_off_total = sum(r['tempo_motor_off'] for r in grupo)
                qtd_pontos_total = sum(r['qtd_pontos'] for r in grupo)
                
                # Atualizar o primeiro registro com dados consolidados
                registros_para_atualizar.append({
                    'id': primeiro['id'],
                    'data_fim': ultimo['data_fim'].strftime('%Y-%m-%d %H:%M:%S'),
                    'km_final': ultimo['km_final'],
                    'distancia': distancia_total,
                    'local_fim': ultimo['local_fim'],
                    'tempo': tempo_total,
                    'tempo_ocioso': tempo_ocioso_total,
                    'tempo_motor_off': tempo_motor_off_total,
                    'qtd_pontos': qtd_pontos_total,
                    'raw_id_fim': ultimo['raw_id_fim'],
                })
                
                # Marcar os demais para dele√ß√£o
                for r in grupo[1:]:
                    ids_para_deletar.append(r['id'])
                
                total_consolidados += len(grupo) - 1
            
            i = j
    
    # Executar atualiza√ß√µes
    if registros_para_atualizar:
        print(f"üìù Atualizando {len(registros_para_atualizar)} registros consolidados...")
        for reg in registros_para_atualizar:
            c.execute("""
                UPDATE deslocamentos 
                SET data_fim = %s, km_final = %s, distancia = %s, local_fim = %s,
                    tempo = %s, tempo_ocioso = %s, tempo_motor_off = %s, 
                    qtd_pontos = %s, raw_id_fim = %s
                WHERE id = %s
            """, (
                reg['data_fim'], reg['km_final'], reg['distancia'], reg['local_fim'],
                reg['tempo'], reg['tempo_ocioso'], reg['tempo_motor_off'],
                reg['qtd_pontos'], reg['raw_id_fim'], reg['id']
            ))
        conn.commit()
    
    # Deletar registros consolidados
    if ids_para_deletar:
        print(f"üóëÔ∏è Removendo {len(ids_para_deletar)} registros duplicados ap√≥s consolida√ß√£o...")
        # Deletar em lotes para evitar query muito grande
        BATCH_SIZE = 100
        for i in range(0, len(ids_para_deletar), BATCH_SIZE):
            batch_ids = ids_para_deletar[i:i + BATCH_SIZE]
            placeholders = ', '.join(['%s'] * len(batch_ids))
            c.execute(f"DELETE FROM deslocamentos WHERE id IN ({placeholders})", batch_ids)
        conn.commit()
    
    conn.close()
    
    print(f"\n‚úÖ Consolida√ß√£o conclu√≠da!")
    print(f"   - Registros consolidados: {total_consolidados}")
    print(f"   - Registros removidos: {len(ids_para_deletar)}")
    print(f"   - Registros atualizados: {len(registros_para_atualizar)}")


def limpar_e_reprocessar():
    """
    Limpa TODOS os deslocamentos e reprocessa do zero.
    USE COM CUIDADO - apenas quando necess√°rio reconstruir tudo.
    """
    print("‚ö†Ô∏è ATEN√á√ÉO: Limpando TODOS os deslocamentos para reprocessamento completo...")
    
    conn = get_connection()
    c = conn.cursor()
    
    # Contar antes
    c.execute("SELECT COUNT(*) FROM deslocamentos")
    qtd_antes = c.fetchone()[0]
    
    # Deletar TODOS os deslocamentos (reprocessar = reconstruir do zero)
    c.execute("DELETE FROM deslocamentos")
    conn.commit()
    conn.close()
    
    print(f"üóëÔ∏è {qtd_antes} deslocamentos removidos.")
    print("üîÑ Iniciando reprocessamento completo...")
    
    # Reprocessar tudo
    processar_deslocamentos(reprocessar_tudo=True)


def remover_duplicatas():
    """
    Remove deslocamentos e posi√ß√µes duplicadas do banco de dados.
    Duplicatas s√£o identificadas por placa + data_inicio + data_fim iguais.
    """
    print("üîç Buscando duplicatas...")
    
    conn = get_connection()
    c = conn.cursor()
    
    # 1. Remover deslocamentos duplicados (mant√©m o de menor ID)
    print("üìã Removendo deslocamentos duplicados...")
    
    # Identificar duplicatas (PostgreSQL syntax)
    duplicatas_query = """
        DELETE FROM deslocamentos 
        WHERE id NOT IN (
            SELECT MIN(id) 
            FROM deslocamentos 
            GROUP BY placa, data_inicio, data_fim
        )
    """
    
    try:
        c.execute(duplicatas_query)
        qtd_desloc = c.rowcount
        print(f"  ‚úÖ {qtd_desloc} deslocamentos duplicados removidos")
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erro ao remover duplicatas de deslocamentos: {e}")
        qtd_desloc = 0
    
    # 2. Remover posi√ß√µes duplicadas (mant√©m a de menor ID)
    print("üìç Removendo posi√ß√µes duplicadas...")
    
    posicoes_query = """
        DELETE FROM posicoes_raw 
        WHERE id NOT IN (
            SELECT MIN(id) 
            FROM posicoes_raw 
            GROUP BY id_veiculo, data_hora
        )
    """
    
    try:
        c.execute(posicoes_query)
        qtd_pos = c.rowcount
        print(f"  ‚úÖ {qtd_pos} posi√ß√µes duplicadas removidas")
    except Exception as e:
        print(f"  ‚ö†Ô∏è Erro ao remover duplicatas de posi√ß√µes: {e}")
        qtd_pos = 0
    
    conn.commit()
    conn.close()
    
    print(f"\nüìä Total removido: {qtd_desloc} deslocamentos + {qtd_pos} posi√ß√µes")


def corrigir_nomes_locais():
    """
    Corrige nomes de locais existentes no banco de dados.
    Remove prefixos verbosos como 'Regi√£o Geogr√°fica Imediata de'.
    """
    print("üìù Corrigindo nomes de locais existentes...")
    
    conn = get_connection()
    c = conn.cursor()
    
    # Substitui√ß√µes a fazer
    substituicoes = [
        ('Regi√£o Geogr√°fica Imediata de ', 'Regi√£o de '),
        ('Regi√£o Geogr√°fica Intermedi√°ria de ', 'Regi√£o de '),
        ('Microrregi√£o de ', ''),
        ('Mesorregi√£o de ', ''),
    ]
    
    total_corrigidos = 0
    
    for antigo, novo in substituicoes:
        # Corrigir local_inicio
        c.execute(f"""
            UPDATE deslocamentos 
            SET local_inicio = REPLACE(local_inicio, %s, %s)
            WHERE local_inicio LIKE %s
        """, (antigo, novo, f'%{antigo}%'))
        total_corrigidos += c.rowcount
        
        # Corrigir local_fim
        c.execute(f"""
            UPDATE deslocamentos 
            SET local_fim = REPLACE(local_fim, %s, %s)
            WHERE local_fim LIKE %s
        """, (antigo, novo, f'%{antigo}%'))
        total_corrigidos += c.rowcount
    
    conn.commit()
    conn.close()
    
    print(f"‚úÖ {total_corrigidos} campos de local corrigidos")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        comando = sys.argv[1]
        
        if comando == "--reprocessar":
            limpar_e_reprocessar()
            # V6: N√£o precisa consolidar, a l√≥gica j√° elimina gaps
        elif comando == "--limpar-duplicatas":
            remover_duplicatas()
        elif comando == "--corrigir-nomes":
            corrigir_nomes_locais()
        elif comando == "--consolidar":
            # Op√ß√£o para consolidar manualmente
            tolerancia = 30  # default
            if len(sys.argv) > 2:
                try:
                    tolerancia = int(sys.argv[2])
                except ValueError:
                    print(f"‚ö†Ô∏è Toler√¢ncia inv√°lida: {sys.argv[2]}. Usando 30 minutos.")
            consolidar_periodos_consecutivos(tolerancia)
        elif comando == "--help":
            print("""
Processador de Deslocamentos v5
================================
Uso: python processor.py [op√ß√£o]

Op√ß√µes:
  (sem op√ß√£o)           Processamento incremental normal + consolida√ß√£o
  --reprocessar         Limpa pendentes e reprocessa tudo + consolida
  --consolidar [min]    Consolida paradas/movimentos fragmentados (default: 30 min)
  --limpar-duplicatas   Remove deslocamentos e posi√ß√µes duplicados
  --corrigir-nomes      Corrige nomes de locais verbosos
  --help                Mostra esta ajuda

L√≥gica V5:
  - MOVIMENTO: velocidade >= 3 km/h
  - PARADA: velocidade < 3 km/h
  - Per√≠odos < 5 min s√£o absorvidos no anterior
  - Paradas < 15 min entre movimentos n√£o fragmentam
  - Per√≠odos "em curso" (< 30 min) n√£o s√£o inseridos
            """)
        else:
            print(f"Op√ß√£o desconhecida: {comando}")
            print("Use --help para ver as op√ß√µes dispon√≠veis")
    else:
        # Processamento normal + consolida√ß√£o autom√°tica
        processar_deslocamentos()
        consolidar_periodos_consecutivos()

